{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aba6eb3-585a-431a-91a8-975060c336b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rosbag\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pyrealsense2 as rs\n",
    "from sensor_msgs.msg import Image, CameraInfo\n",
    "from cv_bridge import CvBridge\n",
    "\n",
    "# Initialize the CvBridge class\n",
    "bridge = CvBridge()\n",
    "\n",
    "# Bag file path\n",
    "bag_file = 'path/to/your.bag'\n",
    "\n",
    "# Create a context for realsense\n",
    "pipeline = rs.pipeline()\n",
    "\n",
    "# Extract data from the bag file\n",
    "with rosbag.Bag(bag_file, 'r') as bag:\n",
    "    for topic, msg, t in bag.read_messages(topics=['/camera/depth/image_raw',\n",
    "                                                   '/camera/color/image_raw',\n",
    "                                                   '/camera/depth/camera_info',\n",
    "                                                   '/camera/color/camera_info',\n",
    "                                                   '/camera/extrinsics/depth_to_color']):\n",
    "        if topic == '/camera/depth/image_raw':\n",
    "            depth_image = bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')\n",
    "        elif topic == '/camera/color/image_raw':\n",
    "            color_image = bridge.imgmsg_to_cv2(msg, 'bgr8')\n",
    "        elif topic == '/camera/depth/camera_info':\n",
    "            depth_intrinsics = rs.intrinsics()\n",
    "            depth_intrinsics.width = msg.width\n",
    "            depth_intrinsics.height = msg.height\n",
    "            depth_intrinsics.ppx = msg.K[2]\n",
    "            depth_intrinsics.ppy = msg.K[5]\n",
    "            depth_intrinsics.fx = msg.K[0]\n",
    "            depth_intrinsics.fy = msg.K[4]\n",
    "            depth_intrinsics.model = rs.distortion.none\n",
    "            depth_intrinsics.coeffs = msg.D\n",
    "        elif topic == '/camera/color/camera_info':\n",
    "            color_intrinsics = rs.intrinsics()\n",
    "            color_intrinsics.width = msg.width\n",
    "            color_intrinsics.height = msg.height\n",
    "            color_intrinsics.ppx = msg.K[2]\n",
    "            color_intrinsics.ppy = msg.K[5]\n",
    "            color_intrinsics.fx = msg.K[0]\n",
    "            color_intrinsics.fy = msg.K[4]\n",
    "            color_intrinsics.model = rs.distortion.none\n",
    "            color_intrinsics.coeffs = msg.D\n",
    "        elif topic == '/camera/extrinsics/depth_to_color':\n",
    "            depth_to_color_extrinsics = rs.extrinsics()\n",
    "            depth_to_color_extrinsics.rotation = msg.rotation\n",
    "            depth_to_color_extrinsics.translation = msg.translation\n",
    "\n",
    "# Assuming depth scale is known or obtained from the RealSense device\n",
    "depth_scale = 0.001  # For example, typical depth scale for RealSense cameras\n",
    "\n",
    "# Create pointcloud object\n",
    "pc = rs.pointcloud()\n",
    "\n",
    "# Generate the pointcloud and texture mappings\n",
    "depth_frame = rs.frame(depth_image)\n",
    "color_frame = rs.frame(color_image)\n",
    "pc.map_to(color_frame)\n",
    "points = pc.calculate(depth_frame)\n",
    "\n",
    "# Get vertices and texture coordinates\n",
    "vertices = np.asanyarray(points.get_vertices())\n",
    "tex_coords = np.asanyarray(points.get_texture_coordinates())\n",
    "\n",
    "# Transform the depth points to the color camera's coordinate system\n",
    "depth_to_color_transform = np.array(depth_to_color_extrinsics.rotation).reshape(3, 3)\n",
    "depth_to_color_translation = np.array(depth_to_color_extrinsics.translation).reshape(3, 1)\n",
    "\n",
    "aligned_points = []\n",
    "for vertex in vertices:\n",
    "    point = np.array([vertex.x, vertex.y, vertex.z]).reshape(3, 1)\n",
    "    transformed_point = depth_to_color_transform @ point + depth_to_color_translation\n",
    "    aligned_points.append(transformed_point)\n",
    "\n",
    "# Project transformed points onto the color image plane\n",
    "projected_points = []\n",
    "for point in aligned_points:\n",
    "    x = point[0] / point[2] * color_intrinsics.fx + color_intrinsics.ppx\n",
    "    y = point[1] / point[2] * color_intrinsics.fy + color_intrinsics.ppy\n",
    "    projected_points.append((x, y))\n",
    "\n",
    "# Visualize the alignment\n",
    "for (x, y) in projected_points:\n",
    "    if 0 <= x < color_image.shape[1] and 0 <= y < color_image.shape[0]:\n",
    "        cv2.circle(color_image, (int(x), int(y)), 2, (0, 0, 255), -1)\n",
    "\n",
    "cv2.imshow('Aligned Depth to Color', color_image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Release the pipeline\n",
    "pipeline.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43904831-2e7d-4010-ab5c-b7d268936c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3a43918-2bce-41a2-a01f-810264b9be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"/calibration/ros2/src/scanner/scanner/2024-07-24_21_38_49.574345.npz\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a857a799-108e-4593-9c6e-a1b75a1fe2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_frames = data[\"color_frames\"]\n",
    "depth_frames = data[\"depth_frames\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a95576d9-8fff-4049-b582-91dd9ba48c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth_frames[0][0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e786f2bb-8aef-4e38-a444-0afb4a7bb622",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in color_frames:\n",
    "    cv2.imshow(color_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
