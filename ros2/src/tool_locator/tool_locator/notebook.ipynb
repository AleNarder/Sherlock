{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyrealsense2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyrealsense2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mrs\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyrealsense2'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pyrealsense2 as rs\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BAG_FILE_          = \"../data/scan4.bag\"\n",
    "CLIPPING_DISTANCE  = 0.25\n",
    "CLIPPING_TOLERANCE = 0.02 \n",
    "SURFACE_RATIO      = 0.75\n",
    "FRAME_WIDTH        = 640\n",
    "FRAME_HEIGHT       = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to resolve request. Request to enable_device_from_file(\"../data/scan4\") was invalid, Reason: Failed to create ros reader: Error opening file: ../data/scan4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m config\u001b[38;5;241m.\u001b[39menable_stream(rs\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mcolor, FRAME_WIDTH, FRAME_HEIGHT, rs\u001b[38;5;241m.\u001b[39mformat\u001b[38;5;241m.\u001b[39mrgb8, \u001b[38;5;241m15\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Start streaming from file\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m profile \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m depth_sensor \u001b[38;5;241m=\u001b[39m profile\u001b[38;5;241m.\u001b[39mget_device()\u001b[38;5;241m.\u001b[39mfirst_depth_sensor()\n\u001b[1;32m     19\u001b[0m depth_scale \u001b[38;5;241m=\u001b[39m depth_sensor\u001b[38;5;241m.\u001b[39mget_depth_scale()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to resolve request. Request to enable_device_from_file(\"../data/scan4\") was invalid, Reason: Failed to create ros reader: Error opening file: ../data/scan4"
     ]
    }
   ],
   "source": [
    "# Create a realsense pipeline\n",
    "pipeline = rs.pipeline()\n",
    "\n",
    "# Create config object\n",
    "config   = rs.config()\n",
    "\n",
    "# Tell config that we will use a recorded device from file to be used by the pipeline through playback.\n",
    "rs.config.enable_device_from_file(config, BAG_FILE_)\n",
    "\n",
    "# Depth stream config\n",
    "config.enable_stream(rs.stream.depth, FRAME_WIDTH, FRAME_HEIGHT, rs.format.z16, 15)\n",
    "# RGB stream config\n",
    "config.enable_stream(rs.stream.color, FRAME_WIDTH, FRAME_HEIGHT, rs.format.rgb8, 15)\n",
    "\n",
    "# Start streaming from file\n",
    "profile = pipeline.start(config)\n",
    "\n",
    "depth_sensor = profile.get_device().first_depth_sensor()\n",
    "depth_scale = depth_sensor.get_depth_scale()\n",
    "\n",
    "# Create an align object\n",
    "# rs.align allows us to perform alignment of depth frames to others frames\n",
    "# The \"align_to\" is the stream type to which we plan to align depth frames.\n",
    "align_to  = rs.stream.color\n",
    "align     = rs.align(align_to)\n",
    "colorizer = rs.colorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_frames (rs_frames):\n",
    "    # Get depth and color frame\n",
    "    depth_frame = rs_frames.get_depth_frame()\n",
    "    color_frame = rs_frames.get_color_frame()\n",
    "\n",
    "    # Convert depth frame to a metric depth map \n",
    "    depth_map = cv2.rotate(np.asanyarray(depth_frame.get_data()), cv2.ROTATE_180) * depth_scale\n",
    "    depth_map = np.where(depth_map == 0, CLIPPING_DISTANCE * 2, depth_map)\n",
    "    \n",
    "    # Convert depth_frame to numpy array to render image in opencv. Used for debug purposes\n",
    "    depth_color_frame = colorizer.colorize(depth_frame)\n",
    "    depth_color_img   = cv2.rotate(np.asanyarray(depth_color_frame.get_data()), cv2.ROTATE_180) \n",
    "    \n",
    "    # Convert color_frame to numpy array to render image in opencv\n",
    "    bgr_color_img = cv2.rotate(np.asanyarray(color_frame.get_data()), cv2.ROTATE_180)\n",
    "    rgb_color_img = cv2.cvtColor(bgr_color_img, cv2.COLOR_BGR2RGB) \n",
    "    return rgb_color_img, depth_map, depth_color_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"Depth Stream\", cv2.WINDOW_AUTOSIZE)\n",
    "cv2.namedWindow(\"Color Stream\", cv2.WINDOW_AUTOSIZE)\n",
    "\n",
    "while True:\n",
    "    # Get frameset of depth\n",
    "    frames = pipeline.wait_for_frames()\n",
    "\n",
    "    # Align the depth frame to color frame\n",
    "    aligned_frames = align.process(frames)\n",
    "\n",
    "    cv_frames = get_cv_frames(aligned_frames)\n",
    "    \n",
    "    cv2.imshow(\"Depth Stream\", cv_frames[0])\n",
    "    cv2.imshow(\"Color Stream\", cv_frames[2])\n",
    "    key = cv2.waitKey(1)\n",
    "    # if pressed escape exit program\n",
    "    if key == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /io/opencv/modules/imgproc/src/median_blur.simd.hpp:880: error: (-215:Assertion failed) src.depth() == CV_8U && (cn == 1 || cn == 3 || cn == 4) in function 'medianBlur'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m aligned_frames \u001b[38;5;241m=\u001b[39m align\u001b[38;5;241m.\u001b[39mprocess(frames)\n\u001b[1;32m     11\u001b[0m _, depth_map, _ \u001b[38;5;241m=\u001b[39m get_cv_frames(aligned_frames)\n\u001b[0;32m---> 13\u001b[0m median \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmedianBlur\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdepth_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaw Depth Stream\u001b[39m\u001b[38;5;124m\"\u001b[39m, depth_map)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#cv2.imshow(\"Depth Stream\", gray_depth_frame)\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/median_blur.simd.hpp:880: error: (-215:Assertion failed) src.depth() == CV_8U && (cn == 1 || cn == 3 || cn == 4) in function 'medianBlur'\n"
     ]
    }
   ],
   "source": [
    "cv2.namedWindow(\"Depth Stream\", cv2.WINDOW_AUTOSIZE)\n",
    "# cv2.namedWindow(\"Raw Depth Stream\", cv2.WINDOW_AUTOSIZE)\n",
    "# cv2.namedWindow(\"Depth Map\", cv2.WINDOW_AUTOSIZE)\n",
    "while True:\n",
    "    # Get frameset of depth\n",
    "    frames = pipeline.wait_for_frames()\n",
    "\n",
    "    # Align the depth frame to color frame\n",
    "    aligned_frames = align.process(frames)\n",
    "\n",
    "    _, depth_map, _ = get_cv_frames(aligned_frames)\n",
    "\n",
    "    median = cv2.medianBlur(depth_map, 25)\n",
    "\n",
    "    cv2.imshow(\"Raw Depth Stream\", depth_map)\n",
    "    #cv2.imshow(\"Depth Stream\", gray_depth_frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    # if pressed escape exit program\n",
    "    if key == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "from utils.roi import ROIWindow\n",
    "\n",
    "cv2.namedWindow(\"Detection Stream\", cv2.WINDOW_KEEPRATIO)\n",
    "\n",
    "roi_tool_w = ROIWindow(\n",
    "    frame_h = FRAME_HEIGHT, \n",
    "    frame_w = FRAME_WIDTH, \n",
    "    win_w   = 5,\n",
    "    win_h   = 25\n",
    ")\n",
    "\n",
    "roi_circles_w = ROIWindow(\n",
    "    frame_h = FRAME_HEIGHT,\n",
    "    frame_w = FRAME_WIDTH,\n",
    "    win_w   = 60,\n",
    "    win_h   = 200\n",
    ")\n",
    "\n",
    "\n",
    "roi_tool_w.calibrate_offset_y(40)\n",
    "\n",
    "roi_circles_w.calibrate_offset_y(40)\n",
    "roi_circles_w.set_color((0, 255, 0))\n",
    "tool_idx = 0\n",
    "\n",
    "while True:\n",
    "    # Get frameset of depth\n",
    "    frames = pipeline.wait_for_frames()\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Align the depth frame to color frame\n",
    "    aligned_frames = align.process(frames)\n",
    "\n",
    "    color_frame, depth_map, _ = get_cv_frames(aligned_frames)\n",
    "    debug_color_frame         = color_frame.copy()\n",
    "    \n",
    "    depth_roi = roi_tool_w.get_window(depth_map)\n",
    "    color_roi = roi_tool_w.get_window(color_frame)\n",
    "\n",
    "    roi_tool_w.apply_window(debug_color_frame)\n",
    "    roi_tool_w.apply_hr_calib_line(debug_color_frame, 75, from_bottom = True)\n",
    "    roi_tool_w.apply_hr_calib_line(debug_color_frame, 15)\n",
    "\n",
    "    depth_mask = np.where(depth_roi < CLIPPING_DISTANCE + CLIPPING_TOLERANCE, 1, 0).astype(np.uint8)\n",
    "    \n",
    "    # avg_depth = np.mean(depth_roi)\n",
    "    # cv2.putText()\n",
    "\n",
    "    masked_roi = cv2.bitwise_and(color_roi, color_roi, mask = depth_mask)\n",
    "\n",
    "    good_surface_ratio = np.sum(depth_mask > 0) / (depth_mask.shape[0] * depth_mask.shape[1])\n",
    "\n",
    "    ready_4_contour = False\n",
    "    if (good_surface_ratio >= SURFACE_RATIO):\n",
    "        # 1. Hough circles method\n",
    "        roi_circles_w.apply_window(debug_color_frame)\n",
    "        circles_roi      = roi_circles_w.get_window(color_frame)\n",
    "        circles_roi_g    = cv2.cvtColor(circles_roi, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        circles          = cv2.HoughCircles(\n",
    "            circles_roi_g,\n",
    "            cv2.HOUGH_GRADIENT_ALT,\n",
    "            1.5,\n",
    "            20,\n",
    "            param1    = 275,\n",
    "            param2    = 0.9,\n",
    "            minRadius = 12,\n",
    "            maxRadius = 90\n",
    "        )\n",
    "        \n",
    "        if circles is not None:\n",
    "\n",
    "            circles = np.uint16(np.around(circles))\n",
    "            centered = False\n",
    "            depth_mask_roi    = roi_circles_w.get_window(depth_map)\n",
    "\n",
    "            for circle in circles[0,:]:\n",
    "                x, y, radius = circle\n",
    "                # draw the outer circle\n",
    "                cv2.circle(circles_roi,(x, y), radius,(0,255,0), 2)\n",
    "                cv2.circle(depth_mask_roi, (x, y), radius, 1, -1)\n",
    "                \n",
    "                # draw the center of the circle\n",
    "                cv2.circle(circles_roi,(x, y), 2, (0,0,255), 3)\n",
    "\n",
    "                centered = abs(x - circles_roi.shape[1] / 2) < 10\n",
    "\n",
    "            if centered:\n",
    "                tool_idx += 1\n",
    "                np.save(\"tool\" + str(tool_idx) + \".npy\", color_frame)\n",
    "                \n",
    "                cv2.circle(circles_roi,(x, y), radius,(0,255,0), 2)\n",
    "                pts = []\n",
    "                while(len(pts) < 30):\n",
    "                    x_p = random.randrange(0, depth_mask_roi.shape[0] - 1)\n",
    "                    y_p = random.randrange(0, depth_mask_roi.shape[1] - 1)\n",
    "                    if (depth_mask_roi[x_p, y_p] <= CLIPPING_DISTANCE + CLIPPING_TOLERANCE):\n",
    "                        pts.append([y_p, x_p])\n",
    "\n",
    "                for i in range(0, 30):\n",
    "                    cv2.circle(circles_roi, pts[i], 2, (255, 0, 0), 1)\n",
    "\n",
    "            roi_circles_w.apply_window_patch(debug_color_frame, circles_roi)\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "    cv2.putText(debug_color_frame, \"FPS: \" + str(round(1 / elapsed, 3)) , (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "    \n",
    "\n",
    "    cv2.imshow(\"Detection Stream\", debug_color_frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    # if pressed escape exit program\n",
    "    if key == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
